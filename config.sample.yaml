---
flowehr_id: sample
location: uksouth
environment: sample
accesses_real_data: false  # Optional
private_dns_zones_rg: sample-rg-name  # Optional

data_source_connections:  # Optional
  - example:
    name: samplesql
    peering:  # Optional
      virtual_network_name: sample-vnet-name
      resource_group_name: sample-rg-name
      dns_zones:
        - samplezone.azure.com
    fqdn: samplesql.database.azure.com
    database: sampledb
    username: adminuser
    password: ${SECRET_PASSWORD_FROM_GH}

transform:  # Optional
  spark_version: 3.3  # Optional
  repositories:  # Optional
    - url: https://github.com/MY_TRANSFORM_CODE_REPO.git
    - url: https://github.com/MY_OTHER_TRANSFORM_CODE_REPO.git
      sha: abcd01abcd01abcd01abcd01abcd01abcd01abcd
  datalake:  # Optional
    zones:
      - Bronze
      - Silver
      - Gold

  unity_catalog:  # Optional. If you wish to disable Unity Catalog, remove this section
    catalog_name: catalog
    catalog_name_prefix: catalog  # Either name, or prefix need to be set
    schema_name: schema
    schema_name_prefix: schema
    datalake_zones:  # From datalake section above, the zones that Unity Catalog will have access to
      - Gold

  unity_catalog_metastore:  # Needs to be present if unity_catalog section is present
    metastore_name: metastore-westeurope  # Setting this will result in a new metastore being deployed
    storage_account_name: stgexampleuc  # Globally unique name for the Metastore storage account
    resource_group_name: examplemetastore  # Name for the resource group for Metastore resources
    metastore_id: a12abc12-abcd-abcd-abcd-abcd1234abcd  # Either metastore_name or metastore_id need to be set

  databricks_account_id: a12abc12-abcd-abcd-abcd-abcd1234abcd  # Databricks Account ID unique per tenant. Required to deploy Unity Catalog

  spark_config:  # Optional
    spark.configuration.key: value
  databricks_secrets:
    cog_services_key: my-super-secret-key  # On Github, this wil lbe a token replacement
  databricks_libraries:  # Optional
    pypi:
      - package: opencensus-ext-azure==1.1.9
      - package: opencensus-ext-logging==0.1.1
        repo: "custom-mirror"
    maven:
      - coordinates: "com.amazon.deequ:deequ:1.0.4"
        repo: "custom-mirror"
        exclusions: ["org.apache.avro:avro"]
    jar:
      - "dbfs:/FileStore/app-0.0.1.jar"
  databricks_cluster:
    node_type:
      min_memory_gb: 128
      min_cores: 16
      local_disk_min_size: 600
      category: "Memory Optimised"
    autotermination_minutes: 120
    runtime_engine: STANDARD  # Optional: STANDARD or PHOTON (https://learn.microsoft.com/en-us/azure/databricks/runtime/photon)
    data_security_mode: SINGLE_USER  # Optional: see https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/cluster#data_security_mode
    num_of_workers: 0  # Set to 0 for single node mode or any number for fixed cluster (ignored if autoscale also defined)
    autoscale:
      min_workers: 1
      max_workers: 3
    init_scripts:
      - /workspaces/FlowEHR/transform/sample_init_script.sh

serve:  # Optional
  github_owner: A-GitHub-Org
  github_app_id: 0000000000000
  github_app_installation_id: 00000000000000

monitoring:  # Optional
  alert_recipients:  # Optional
    - name: person
      email: person@example.com
  network_watcher:  # Optional, required if accesses_real_data
    name: NetworkWatcher_location
    resource_group_name: NetworkWatcherRG
